---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.0'
      jupytext_version: 1.0.0
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

# Experimenting with H2O3

## Import H2O libraries

```{python}
import h2o
from h2o.estimators.gbm import H2OGradientBoostingEstimator as GBM
from h2o.grid.grid_search import H2OGridSearch
import matplotlib.pyplot as plt
```

```{python}
# Initializing h2o
h2o.init()
```

```{python}
# Import data

data = h2o.import_file("/Users/steliosrammos/Documents/Education/Maastricht/DKE-Year3/BachelorThesis/bachelor_thesis/data/processed/data_classifier_s.csv")
data.describe()
```

```{python}
# Set predictor and response column names
predictors = data.columns[1:-2]

data["got_go"] = data["got_go"].asfactor()
response = "got_go"
```

```{python}
# train, calib, test, valid = data.split_frame(ratios=[0.70,0.05, 0.15], seed=1)
train, valid = data.split_frame(ratios=[0.75], seed=1)
```

```{python}
print("Train Frame of shape: {}".format(train.shape))
# print("Calibration Frame of shape: {}".format(calib.shape))
# print("Test Frame of shape: {}".format(test.shape))
print("Validation Frame of shape: {}".format(valid.shape))
```

```{python}
ntrees_opt = [100,150,200]
learn_rate_opt = [0.1,0.2]
seed = [1]
hyper_parameters = {"ntrees": ntrees_opt,"learn_rate":learn_rate_opt,"seed":seed}

gs = H2OGridSearch(H2OGradientBoostingEstimator(),
hyper_params=hyper_parameters)
gs.train(x=predictors, y=response, training_frame=train, validation_frame=valid)
```

```{python}
def get_auc(model, parameters):
    print("Model {}: \n".format(model.model_id))
    print('Training score: {}'.format(model.auc(train=True)))
    print('Validation score: {} \n'.format(model.auc(valid=True)))

    if parameters:
        print("Model Parameters: \n")
        
        for key, value in enumerate(hyper_parameters):
            print("{}: {}".format(value, g.params[value]))

    print("\n ######################################################################## \n")

def get_models_auc(models, parameters=False):

    print("######################################################################## \n")
    
    if models is list:
        for model in models:
            get_auc(model, parameters)
    else:
        get_auc(models, parameters)
```

```{python}
gs_calib = H2OGridSearch(H2OGradientBoostingEstimator(calibrate_model = True, calibration_frame = calib), hyper_params=hyper_parameters)
gs_calib.train(x=predictors, y=response, training_frame=train, validation_frame=valid)                                           
```

```{python}
gs_ordered = gs.get_grid(sort_by='auc', decreasing=True)
best_gbm = gs_ordered[0]
```

```{python}
gs_calib_ordered = gs_calib.get_grid(sort_by='auc', decreasing=True)
best_gbm_calib = gs_calib_ordered[0]
```

```{python}
get_models_auc(best_gbm)
```

```{python}
get_models_auc(best_gbm_calib)
```

```{python}
predictions = best_gbm.predict(train)
```

```{python}
calib_predictions = best_gbm_calib.predict(train)
```

```{python}
# p0 = predictions['p0'].cumsum().as_data_frame().values
# p0_calib = calib_predictions['cal_p0'].cumsum().as_data_frame().values
# plt.plot(p0)
# plt.plot(p0_calib)
```

```{python}
# p1 = predictions['p1'].cumsum().as_data_frame().values
# p1_calib = calib_predictions['cal_p1'].cumsum().as_data_frame().values
# plt.plot(p1)
# plt.plot(p1_calib)
```

```{python}
best_gbm
```

```{python}

```
