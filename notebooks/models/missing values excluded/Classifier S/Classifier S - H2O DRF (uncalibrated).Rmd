---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.0'
      jupytext_version: 1.0.0
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

# Classifier S with H2O - DRF

## Imports

```{python}
# H2O
import h2o

# Data processing
import pandas as pd
import numpy as np

# Visualization
import matplotlib.pyplot as plt
```

```{python}
h2o.init()
```

## Import Data

```{python}
data = h2o.import_file('/Users/steliosrammos/Documents/Education/Maastricht/DKE-Year3/BachelorThesis/bachelor_thesis/data/processed/classifier_s/data_classifier_s.csv')
train_data = h2o.import_file('/Users/steliosrammos/Documents/Education/Maastricht/DKE-Year3/BachelorThesis/bachelor_thesis/data/processed/classifier_s/train_classifier_s.csv')
test_data = h2o.import_file('/Users/steliosrammos/Documents/Education/Maastricht/DKE-Year3/BachelorThesis/bachelor_thesis/data/processed/classifier_s/test_classifier_s.csv')
```

```{python}
# Parse categorical data
categorical = ['HulpeloosheidLevel', 'MagnificatieLevel', 'RuminatieLevel', 'TotaalLevel', 'got_go']

for category in categorical:
    train_data[category] = train_data[category].asfactor()
```

```{python}
# Set predictors and response columns
features = train_data.columns
X = features[:-1]
y = features[-1]
```

```{python}
# Split train, test, valid
train, valid = train_data.split_frame([0.8])
```

## Distributed Random Forest Estimator (Calibrated)

```{python}
from h2o.estimators.random_forest import H2ORandomForestEstimator
from h2o.grid.grid_search import H2OGridSearch
from sklearn.metrics import accuracy_score
from src.func.model_func import get_metrics
```

```{python}
estimator = H2ORandomForestEstimator(nfolds=5, balance_classes=True, seed=55)
```

```{python}
hyper_parameters = {
    'ntrees': [50, 100, 200],
    'max_depth': [5, 10, 20, 30, 50],
    'fold_assignment':['Stratified']
}

grid_search = H2OGridSearch(estimator, hyper_params=hyper_parameters)
```

```{python}
grid_search.train(x=X, y=y, training_frame=train, validation_frame=valid)
```

```{python}
sorted_grid = grid_search.get_grid(sort_by='auc',decreasing=True)

best_max_depth  = sorted_grid.sorted_metric_table()['max_depth'][0]
best_ntrees     = sorted_grid.sorted_metric_table()['ntrees'][0]
best_auc        = sorted_grid.sorted_metric_table()['auc'][0]
best_fold_assignment = sorted_grid.sorted_metric_table()['fold_assignment'][0]

print('Best max_depth.....', best_max_depth)
print('Best ntrees........', best_ntrees)
print('Best auc...........', best_auc)
print('Best fold assignment...........', best_fold_assignment)
```

```{python}
sorted_grid.sorted_metric_table().head()
```

```{python}
# Evaluate
best_drf = sorted_grid[0]
predictions = best_drf.predict(test_data).as_data_frame()
```

```{python}
print("Accuracy: ", accuracy_score(test_data.as_data_frame().iloc[:,-1], predictions["predict"]))
get_metrics(test_data.as_data_frame().iloc[:,-1], proba_predicted_y=predictions["p1"].values)
```

```{python}
model_path = h2o.save_model(model=best_drf, path="/Users/steliosrammos/Documents/Education/Maastricht/DKE-Year3/BachelorThesis/bachelor_thesis/models/classifier_s/uncalibrate/classifier_s_h2o", force=True)

# load the model
# saved_model = h2o.load_model(model_path)

# Current build: /Users/steliosrammos/Documents/Education/Maastricht/DKE-Year3/BachelorThesis/bachelor_thesis/models/classifier_s/uncalibrate/classifier_s_h2o/Grid_DRF_py_3_sid_b093_model_python_1553073290449_154565_model_6
```

### Check calibration

```{python}
model_path = "/Users/steliosrammos/Documents/Education/Maastricht/DKE-Year3/BachelorThesis/bachelor_thesis/models/classifier_s/uncalibrate/classifier_s_h2o/Grid_DRF_py_3_sid_b093_model_python_1553073290449_154565_model_6"
model = h2o.load_model(model_path)
```

```{python}
predictions = model.predict(test_data)
```

```{python}
uncalibrated_rates = [predictions['p0'].mean(), predictions['p1'].mean()]
print(calibrated_rates)
```

```{python}
actual_rates = [data.as_data_frame()['got_go'].value_counts()[0]/data.shape[0], data.as_data_frame()['got_go'].value_counts()[1]/data.shape[0]]
print(actual_rates)
```

```{python}
non_calib_pred = predictions[:, ['predict', 'p0', 'p1']].as_data_frame()
```

```{python}
from sklearn.calibration import calibration_curve
```

```{python}
y_test = test_data['got_go'].as_data_frame().values
non_prob_pos = predictions['p1'].as_data_frame().values

fraction_of_positives_non, mean_predicted_value_non = calibration_curve(y_test, non_prob_pos, n_bins=10)
fraction_of_positives_non, mean_predicted_value_non = zip(*sorted(zip(fraction_of_positives_non,mean_predicted_value_non),key=lambda x: x[0]))

fig = plt.figure(figsize=(10, 10))
plt.plot([0, 1], [0, 1], "k:", label="Perfectly calibrated")
plt.plot(fraction_of_positives_non, mean_predicted_value_non, "s-", label="Uncalibrated")
plt.legend(loc="best")
non_prob_pos = predictions['p1'].as_data_frame().values
```

```{python}

```
