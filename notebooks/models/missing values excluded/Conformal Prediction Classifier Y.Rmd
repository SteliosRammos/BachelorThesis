---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.0'
      jupytext_version: 1.0.0
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

# Conformal Prediction with corrected Classifier Y 


## Imports

```{python}
# General packages
import h2o
import pandas as pd
import numpy as np

# Scikit-learn
from sklearn.model_selection import train_test_split
from sklearn.model_selection import ShuffleSplit
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score, accuracy_score

# Conformal framework
from nonconformist.cp import TcpClassifier, IcpClassifier
from nonconformist.nc import NcFactory
from nonconformist.base import ClassifierAdapter
from nonconformist.nc import ClassifierNc
from nonconformist.nc import ClassificationErrFunc
```

## Load Data

```{python}
def load_data():
    data = pd.read_csv("/Users/steliosrammos/Documents/Education/Maastricht/DKE-Year3/BachelorThesis/bachelor_thesis/data/processed/data_classifier_y_labld_weights.csv", sep=";")

    X = data.iloc[:1000, 0:-2]
    y = data.iloc[:1000,-1]

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)
#     test_data = pd.concat([X_test, y_test], axis=1)

    return X_train, X_test, y_train, y_test
```

## SciKit Learn Conformal Model

```{python}
## SCIKIT MODEL ##

def train_conformal(X_train, X_test, y_train):
    # Create classifier
    # model = RandomForestClassifier(n_estimators=100,random_state=1)
    model = SVC(probability=True, gamma='scale', random_state=1)

    # Create a default nonconformity function
    nc = NcFactory.create_nc(model)

    # Create a transductive conformal classifier
    tcp = TcpClassifier(nc)

    # Fit the TCP using the proper training set
    tcp.fit(X_train, y_train)

    # Produce predictions for the test set, with confidence 95%
    predictions = tcp.predict_conf(X_test.values)

    return predictions

def get_best_pred_indeces(predictions, significance):
    
    i = 0 
    best_pred_indeces = []
    
    for prediction in predictions:

        confidence = pred[1]
        if prediction[1] >= (1-significance):
            best_pred_indeces.append(i)
    
        i += 1
        
    return best_pred_indeces
```

```{python}
stop = False
X_train, X_test, y_train, y_test = load_data()
print('Remaining unlabeled: {} \n'.format(y_test.shape[0]))

while not stop:
    predictions = train_conformal(X_train, X_test, y_train)
    best_predictions_indeces = get_best_pred_indeces(predictions, 0.05)
    print('Number of good predictions: {}'.format(len(best_predictions_indeces)))
    
    if y_test.shape[0] == 0 or len(best_predictions_indeces) == 0:
        stop = True
    else:
        best_predictions_indeces = get_best_pred_indeces(predictions, 0.05)

        X_train.append(X_test.iloc[best_predictions_indeces,:])
        y_train.append(pd.Series(predictions[best_predictions_indeces,0]))
        
        accuracy = accuracy_score(y_test, predictions[:, 0])
        
        X_test = X_test.drop(X_test.index[best_predictions_indeces], axis=0)
        y_test = y_test.drop(y_test.index[best_predictions_indeces], axis=0)
        
        print('Remaining unlabeled: {} \n'.format(y_test.shape[0]))
        print('Accuracy: {} \n'.format(accuracy))

```

## H2O Conformal Model

### Extend nonconformist with classifier adapter for h2o models

```{python}
class MyClassifierAdapter(ClassifierAdapter):
    
    def __init__(self, model, fit_params=None):
        super(MyClassifierAdapter, self).__init__(model, fit_params)
        self.normalizer = None
        self.err_func=MarginErrFunc()
        
    def fit(self, x, y):
        '''
            x is a numpy.array of shape (n_train, n_features)
            y is a numpy.array of shape (n_train)
            
            Here, do what is necessary to train the underlying model
            using the supplied training data
        '''
        
#         data_h2o = h2o.H2OFrame(data_labld)

        print('Using overwritten fit.')
        x = h2o.H2OFrame(x)
        y = h2o.H2OFrame(y)
        self.model.fit(x, y, verbose=False)
        
        return self.model
    
    def predict(self, x):
        '''
            Obtain predictions from the underlying model
            
            Make sure this function returns an output that is compatible with
            the nonconformity function used. For default nonconformity functions,
            output from this function should be class probability estimates in
            a numpy.array of shape (n_test, n_classes)
        '''
#         print('Using overwritten predict.')
#         predictions = self.model.predict(x)
        exit()
#         return predictions
    
    def score(self, x, y=None):
        """Calculates the nonconformity score of a set of samples.
        Parameters
        ----------
        x : numpy array of shape [n_samples, n_features]
            Inputs of examples for which to calculate a nonconformity score.
        y : numpy array of shape [n_samples]
            Outputs of examples for which to calculate a nonconformity score.
        Returns
        -------
        nc : numpy array of shape [n_samples]
            Nonconformity scores of samples.
        """
        x = h2o.H2OFrame(x)
        y = h2o.H2OFrame(y)

        prediction = self.model.predict(x)
        n_test = x.shape[0]
        if self.normalizer is not None:
            norm = self.normalizer.score(x) + self.beta
        else:
            norm = np.ones(n_test)
#             print(norm)

        score = self.err_func.apply(prediction, y) / norm
        
#         score = h2o.H2OFrame(score)
#         print(score)
    
        return score
    
class MarginErrFunc(ClassificationErrFunc):
    """
    Calculates the margin error.
    For each correct output in ``y``, nonconformity is defined as
    .. math::
        0.5 - \dfrac{\hat{P}(y_i | x) - max_{y \, != \, y_i} \hat{P}(y | x)}{2}
    """

    def __init__(self):
        super(MarginErrFunc, self).__init__()

    def apply(self, prediction, y):
        prob = np.zeros(y.shape[0], dtype=np.float32)
        for i, y_ in enumerate(y):
            if y_ >= prediction.shape[1]:
                prob[i] = 0
            else:
                prob[i] = prediction[i, int(y_)]
                prediction[i, int(y_)] = -np.inf
        
        return 0.5 - ((prob - prediction.max()) / 2)
```

```{python}
try:
    h2o.connect()
except: 
    h2o.init()
```

```{python}
# ## H2O MODELS ##

# # Create/load the underlying model


# # h2o model (uncalibrated)
# # clf_y = h2o.load_model('/private/tmp/correct_classifier_y/Grid_GBM_py_5_sid_a301_model_python_1551863370174_1_model_5')

# # h2o model (uncalibrated)
# # clf_y = h2o.load_model('/private/tmp/correct_calibrated_classifier_y/Grid_GBM_py_11_sid_a301_model_python_1551863370174_1816_model_1')

# model = MyClassifierAdapter(clf_y)

# # Create a default nonconformity function
# # nc = ClassifierNc(corrected_clf_y)

# # Create a transductive conformal classifier
# if model is not None:
#     tcp = TcpClassifier(model)
# else:
#     print('Failed to build tcp model.')
```

```{python}
# Fit the TCP using the proper training set
tcp.fit(X_train, y_train)
```

```{python}
# Produce predictions for the test set, with confidence 99%

# prediction_probas = tcp.predict(X_test.values, significance=0.01)
# prediction_probas = tcp.predict_conf(X_test.values)
```

```{python}
for class_region in prediction_probas:
    print(class_region)
    print(class_region.all())
    print('\n ######################### \n')
```

```{python}
accuracy_score(y_test, predicted_labels)
```
